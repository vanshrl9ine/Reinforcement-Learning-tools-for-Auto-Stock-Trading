{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29853799-20a5-4196-b857-879d781aeb1b",
   "metadata": {},
   "source": [
    "# **_Reinforcement Learning tools for Auto-Stock Trading_**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd62e2e-2265-46d6-b8c6-d00b3214467f",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc5a494-5c1b-4cc0-83e5-efb4c18a4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Data Science Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a144855a-0f1b-4e2c-80a2-b2331979704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\yfinance\\base.py:48: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _empty_series = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "#Finrl utilities\n",
    "from finrl import config\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37161da-a220-490f-9b67-6acfe3b850e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Utilities\n",
    "import datetime\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c54ce5-396f-42fb-a582-bc80abd87822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make finrl imports accessible\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b012c6e-f473-4110-852f-de9cee7ad206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup libraries\n",
    "from __future__ import annotations\n",
    "#postponed evaluation of type annotations and evaluation available at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c72d02-9a7c-43fe-a432-6921f1d86a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other imports will be used wherever applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfed73f-b71d-450e-8532-471fc33abde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symbols of BSE SENSEX30 whose data is to be downloaded\n",
    "# symbols = [\n",
    "#     'AXISBANK.BO', 'BAJAJ-AUTO.BO', 'BAJFINANCE.BO', 'BAJAJFINSV.BO',\n",
    "#     'BHARTIARTL.BO', 'DRREDDY.BO', 'HCLTECH.BO', 'JSWSTEEL.BO', 'HDFCBANK.BO',\n",
    "#     'HINDUNILVR.BO', 'ICICIBANK.BO', 'INDUSINDBK.BO', 'INFY.BO', 'ITC.BO',\n",
    "#     'KOTAKBANK.BO', 'LT.BO', 'M&M.BO', 'MARUTI.BO', 'NESTLEIND.BO',\n",
    "#     'NTPC.BO', 'ONGC.BO', 'POWERGRID.BO', 'RELIANCE.BO', 'SBIN.BO',\n",
    "#     'SUNPHARMA.BO', 'TCS.BO', 'TECHM.BO', 'TITAN.BO', 'ULTRACEMCO.BO','ASIANPAINT.BO'\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09ec60f-d1f4-4b21-97a6-60fe0c7cc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globally accesible training and trading s/e\n",
    "TRAIN_START_DATE = '2024-08-16 09:15:00+05:30'\n",
    "TRAIN_END_DATE = '2024-09-25 15:25:00+05:30'\n",
    "TRADE_START_DATE = '2024-09-25 15:25:00+05:30'\n",
    "TRADE_END_DATE = '2024-10-08 14:00:00+05:30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70746a8e-df0e-49b5-a146-21dab4e23a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How we downloaded the data\n",
    "# df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                                 end_date = TRADE_END_DATE,\n",
    "#                                 ticker_list = symbols).fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecee02-4dd1-485e-8d14-f77c820c7b47",
   "metadata": {},
   "source": [
    "### 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b33b42-1022-48ba-9bb4-724b1fa70c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('datasets/intraday_data_by_ticker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c5e44b-1124-4426-87de-925b8c8fff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323.0</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date         open         high          low  \\\n",
       "0  2024-08-16 09:15:00+05:30  3056.000000  3056.000000  3026.600098   \n",
       "1  2024-08-16 09:15:00+05:30  1159.599976  1163.550049  1156.750000   \n",
       "2  2024-08-16 09:15:00+05:30  9770.000000  9775.299805  9740.000000   \n",
       "3  2024-08-16 09:15:00+05:30  1535.900024  1539.900024  1535.199951   \n",
       "4  2024-08-16 09:15:00+05:30  6509.299805  6509.299805  6472.450195   \n",
       "\n",
       "         close  volume            tic  \n",
       "0  3028.350098   323.0  ASIANPAINT.BO  \n",
       "1  1162.949951  4737.0    AXISBANK.BO  \n",
       "2  9770.000000   105.0  BAJAJ-AUTO.BO  \n",
       "3  1538.400024  1689.0  BAJAJFINSV.BO  \n",
       "4  6487.700195  1716.0  BAJFINANCE.BO  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19eecd6d-8e85-4f7e-a6b3-542e23cab110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82740 entries, 0 to 82739\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    82740 non-null  object \n",
      " 1   open    82473 non-null  float64\n",
      " 2   high    82473 non-null  float64\n",
      " 3   low     82473 non-null  float64\n",
      " 4   close   82473 non-null  float64\n",
      " 5   volume  82473 non-null  float64\n",
      " 6   tic     82740 non-null  object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d14f0-5205-4096-a6e5-19151dc53ebc",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febd40c0-9d74-44a1-9fcf-a3b6f7b7bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "from finrl.config import INDICATORS\n",
    "from dataprocessing import FeatureEngineer, load_dataset, data_split, convert_to_datetime\n",
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                      tech_indicator_list = INDICATORS,\n",
    "                      use_vix=False,\n",
    "                      use_turbulence=True,\n",
    "                      user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083563ce-5668-49e3-abed-4c42a4bfa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=pd.read_csv(\"intraday_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a3ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323.0</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date         open         high  \\\n",
       "0           0  2024-08-16 09:15:00+05:30  3056.000000  3056.000000   \n",
       "1           1  2024-08-16 09:15:00+05:30  1159.599976  1163.550049   \n",
       "2           2  2024-08-16 09:15:00+05:30  9770.000000  9775.299805   \n",
       "3           3  2024-08-16 09:15:00+05:30  1535.900024  1539.900024   \n",
       "4           4  2024-08-16 09:15:00+05:30  6509.299805  6509.299805   \n",
       "\n",
       "           low        close  volume            tic  macd      boll_ub  \\\n",
       "0  3026.600098  3028.350098   323.0  ASIANPAINT.BO   0.0  3054.287317   \n",
       "1  1156.750000  1162.949951  4737.0    AXISBANK.BO   0.0  3054.287317   \n",
       "2  9740.000000  9770.000000   105.0  BAJAJ-AUTO.BO   0.0  3054.287317   \n",
       "3  1535.199951  1538.400024  1689.0  BAJAJFINSV.BO   0.0  3054.287317   \n",
       "4  6472.450195  6487.700195  1716.0  BAJFINANCE.BO   0.0  3054.287317   \n",
       "\n",
       "       boll_lb  rsi_30     cci_30  dx_30  close_30_sma  close_60_sma  \\\n",
       "0  3015.962683   100.0  66.666667  100.0   3028.350098   3028.350098   \n",
       "1  3015.962683   100.0  66.666667  100.0   1162.949951   1162.949951   \n",
       "2  3015.962683   100.0  66.666667  100.0   9770.000000   9770.000000   \n",
       "3  3015.962683   100.0  66.666667  100.0   1538.400024   1538.400024   \n",
       "4  3015.962683   100.0  66.666667  100.0   6487.700195   6487.700195   \n",
       "\n",
       "   turbulence  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043a05a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0348cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323.0</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date         open         high          low  \\\n",
       "0  2024-08-16 09:15:00+05:30  3056.000000  3056.000000  3026.600098   \n",
       "1  2024-08-16 09:15:00+05:30  1159.599976  1163.550049  1156.750000   \n",
       "2  2024-08-16 09:15:00+05:30  9770.000000  9775.299805  9740.000000   \n",
       "3  2024-08-16 09:15:00+05:30  1535.900024  1539.900024  1535.199951   \n",
       "4  2024-08-16 09:15:00+05:30  6509.299805  6509.299805  6472.450195   \n",
       "\n",
       "         close  volume            tic  macd      boll_ub      boll_lb  rsi_30  \\\n",
       "0  3028.350098   323.0  ASIANPAINT.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "1  1162.949951  4737.0    AXISBANK.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "2  9770.000000   105.0  BAJAJ-AUTO.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "3  1538.400024  1689.0  BAJAJFINSV.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "4  6487.700195  1716.0  BAJFINANCE.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "\n",
       "      cci_30  dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  66.666667  100.0   3028.350098   3028.350098         0.0  \n",
       "1  66.666667  100.0   1162.949951   1162.949951         0.0  \n",
       "2  66.666667  100.0   9770.000000   9770.000000         0.0  \n",
       "3  66.666667  100.0   1538.400024   1538.400024         0.0  \n",
       "4  66.666667  100.0   6487.700195   6487.700195         0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b299a545-307a-4d24-a530-9c7a1e0e84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b45789e-5f8a-4a0d-a1ba-070d4601b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df[\"tic\"].unique().tolist()\n",
    "# only apply to daily level data, need to fix for minute level\n",
    "list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "df_full = df_full[df_full['date'].isin(df['date'])]\n",
    "df_full = df_full.sort_values(['date','tic'])\n",
    "df_full = df_full.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe4ccb1a-fe6a-41e1-95fe-8a3363465c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date            tic         open         high  \\\n",
       "0  2024-08-16 09:15:00+05:30  ASIANPAINT.BO  3056.000000  3056.000000   \n",
       "1  2024-08-16 09:15:00+05:30    AXISBANK.BO  1159.599976  1163.550049   \n",
       "2  2024-08-16 09:15:00+05:30  BAJAJ-AUTO.BO  9770.000000  9775.299805   \n",
       "3  2024-08-16 09:15:00+05:30  BAJAJFINSV.BO  1535.900024  1539.900024   \n",
       "4  2024-08-16 09:15:00+05:30  BAJFINANCE.BO  6509.299805  6509.299805   \n",
       "\n",
       "           low        close  volume  macd      boll_ub      boll_lb  rsi_30  \\\n",
       "0  3026.600098  3028.350098   323.0   0.0  3054.287317  3015.962683   100.0   \n",
       "1  1156.750000  1162.949951  4737.0   0.0  3054.287317  3015.962683   100.0   \n",
       "2  9740.000000  9770.000000   105.0   0.0  3054.287317  3015.962683   100.0   \n",
       "3  1535.199951  1538.400024  1689.0   0.0  3054.287317  3015.962683   100.0   \n",
       "4  6472.450195  6487.700195  1716.0   0.0  3054.287317  3015.962683   100.0   \n",
       "\n",
       "      cci_30  dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  66.666667  100.0   3028.350098   3028.350098         0.0  \n",
       "1  66.666667  100.0   1162.949951   1162.949951         0.0  \n",
       "2  66.666667  100.0   9770.000000   9770.000000         0.0  \n",
       "3  66.666667  100.0   1538.400024   1538.400024         0.0  \n",
       "4  66.666667  100.0   6487.700195   6487.700195         0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2577b7-eabd-4f2c-a467-cb5584c94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05041644-b750-457e-81c5-29c56fc1d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date            tic         open         high  \\\n",
       "0  2024-08-16 09:15:00+05:30  ASIANPAINT.BO  3056.000000  3056.000000   \n",
       "1  2024-08-16 09:15:00+05:30    AXISBANK.BO  1159.599976  1163.550049   \n",
       "2  2024-08-16 09:15:00+05:30  BAJAJ-AUTO.BO  9770.000000  9775.299805   \n",
       "3  2024-08-16 09:15:00+05:30  BAJAJFINSV.BO  1535.900024  1539.900024   \n",
       "4  2024-08-16 09:15:00+05:30  BAJFINANCE.BO  6509.299805  6509.299805   \n",
       "\n",
       "           low        close  volume  macd      boll_ub      boll_lb  rsi_30  \\\n",
       "0  3026.600098  3028.350098   323.0   0.0  3054.287317  3015.962683   100.0   \n",
       "1  1156.750000  1162.949951  4737.0   0.0  3054.287317  3015.962683   100.0   \n",
       "2  9740.000000  9770.000000   105.0   0.0  3054.287317  3015.962683   100.0   \n",
       "3  1535.199951  1538.400024  1689.0   0.0  3054.287317  3015.962683   100.0   \n",
       "4  6472.450195  6487.700195  1716.0   0.0  3054.287317  3015.962683   100.0   \n",
       "\n",
       "      cci_30  dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  66.666667  100.0   3028.350098   3028.350098         0.0  \n",
       "1  66.666667  100.0   1162.949951   1162.949951         0.0  \n",
       "2  66.666667  100.0   9770.000000   9770.000000         0.0  \n",
       "3  66.666667  100.0   1538.400024   1538.400024         0.0  \n",
       "4  66.666667  100.0   6487.700195   6487.700195         0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067ab770-a250-4ae6-9192-79a47e011ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d8ef628-f80f-4d6d-9a2f-b626ad01064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split1(df, start, end, target_date_col=\"date\"):\n",
    "    \"\"\"\n",
    "    Split the dataset into training or testing using date and time with timezone.\n",
    "    \n",
    "    :param df: pandas dataframe\n",
    "    :param start: start date in 'YYYY-MM-DD HH:MM:SS+TZ' format\n",
    "    :param end: end date in 'YYYY-MM-DD HH:MM:SS+TZ' format\n",
    "    :param target_date_col: the column name representing the date\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    # Ensure the target_date_col is in datetime format with timezone\n",
    "    df[target_date_col] = pd.to_datetime(df[target_date_col])\n",
    "    \n",
    "    # Filtering the data between start and end dates\n",
    "    data = df[(df[target_date_col] >= pd.Timestamp(start)) & (df[target_date_col] < pd.Timestamp(end))]\n",
    "    \n",
    "    # Sorting the data by date and \"tic\" column\n",
    "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
    "    \n",
    "    # Re-indexing based on the factorized target_date_col\n",
    "    data.index = data[target_date_col].factorize()[0]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81504d-0a4a-47c0-aeb3-ecda859ff39b",
   "metadata": {},
   "source": [
    "### 4.Splitting Training and Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1228f57c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_datalala.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_datalala.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m trade\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_datalala.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_datalala.csv'"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('train_data.csv')\n",
    "trade=pd.read_csv('trade_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10ae81c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65250</td>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3262.199951</td>\n",
       "      <td>3244.149902</td>\n",
       "      <td>3260.850098</td>\n",
       "      <td>1336</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>5.693770</td>\n",
       "      <td>3253.649352</td>\n",
       "      <td>3224.380653</td>\n",
       "      <td>63.582353</td>\n",
       "      <td>266.933037</td>\n",
       "      <td>47.135347</td>\n",
       "      <td>3236.245003</td>\n",
       "      <td>3227.441671</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65251</td>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1266.150024</td>\n",
       "      <td>1269.449951</td>\n",
       "      <td>1262.199951</td>\n",
       "      <td>1265.050049</td>\n",
       "      <td>7455</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>3.291383</td>\n",
       "      <td>1271.731478</td>\n",
       "      <td>1252.638530</td>\n",
       "      <td>61.074894</td>\n",
       "      <td>89.119652</td>\n",
       "      <td>17.176047</td>\n",
       "      <td>1259.620003</td>\n",
       "      <td>1256.490835</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65252</td>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>12427.200200</td>\n",
       "      <td>12460.000000</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>346</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>12.589037</td>\n",
       "      <td>12412.230480</td>\n",
       "      <td>12335.739450</td>\n",
       "      <td>55.121774</td>\n",
       "      <td>182.692533</td>\n",
       "      <td>46.939163</td>\n",
       "      <td>12359.558270</td>\n",
       "      <td>12362.732490</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65253</td>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1947.449951</td>\n",
       "      <td>1933.500000</td>\n",
       "      <td>1946.650024</td>\n",
       "      <td>2017</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>6.185544</td>\n",
       "      <td>1937.594372</td>\n",
       "      <td>1896.865637</td>\n",
       "      <td>75.552570</td>\n",
       "      <td>301.805853</td>\n",
       "      <td>60.999199</td>\n",
       "      <td>1915.625000</td>\n",
       "      <td>1912.027500</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65254</td>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>7619.350098</td>\n",
       "      <td>7626.700195</td>\n",
       "      <td>7606.549805</td>\n",
       "      <td>7609.450195</td>\n",
       "      <td>811</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>5.184029</td>\n",
       "      <td>7634.889583</td>\n",
       "      <td>7581.715398</td>\n",
       "      <td>52.200986</td>\n",
       "      <td>51.249181</td>\n",
       "      <td>2.922274</td>\n",
       "      <td>7608.251660</td>\n",
       "      <td>7603.052515</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date          open          high  \\\n",
       "0       65250  2024-09-26 09:15:00+05:30   3250.000000   3262.199951   \n",
       "1       65251  2024-09-26 09:15:00+05:30   1266.150024   1269.449951   \n",
       "2       65252  2024-09-26 09:15:00+05:30  12427.200200  12460.000000   \n",
       "3       65253  2024-09-26 09:15:00+05:30   1940.300049   1947.449951   \n",
       "4       65254  2024-09-26 09:15:00+05:30   7619.350098   7626.700195   \n",
       "\n",
       "            low         close  volume            tic       macd       boll_ub  \\\n",
       "0   3244.149902   3260.850098    1336  ASIANPAINT.BO   5.693770   3253.649352   \n",
       "1   1262.199951   1265.050049    7455    AXISBANK.BO   3.291383   1271.731478   \n",
       "2  12396.400390  12396.400390     346  BAJAJ-AUTO.BO  12.589037  12412.230480   \n",
       "3   1933.500000   1946.650024    2017  BAJAJFINSV.BO   6.185544   1937.594372   \n",
       "4   7606.549805   7609.450195     811  BAJFINANCE.BO   5.184029   7634.889583   \n",
       "\n",
       "        boll_lb     rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0   3224.380653  63.582353  266.933037  47.135347   3236.245003   3227.441671   \n",
       "1   1252.638530  61.074894   89.119652  17.176047   1259.620003   1256.490835   \n",
       "2  12335.739450  55.121774  182.692533  46.939163  12359.558270  12362.732490   \n",
       "3   1896.865637  75.552570  301.805853  60.999199   1915.625000   1912.027500   \n",
       "4   7581.715398  52.200986   51.249181   2.922274   7608.251660   7603.052515   \n",
       "\n",
       "   turbulence  \n",
       "0  365.729838  \n",
       "1  365.729838  \n",
       "2  365.729838  \n",
       "3  365.729838  \n",
       "4  365.729838  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf0c9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "trade.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b172621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69240"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23ff4a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3262.199951</td>\n",
       "      <td>3244.149902</td>\n",
       "      <td>3260.850098</td>\n",
       "      <td>1336</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>5.693770</td>\n",
       "      <td>3253.649352</td>\n",
       "      <td>3224.380653</td>\n",
       "      <td>63.582353</td>\n",
       "      <td>266.933037</td>\n",
       "      <td>47.135347</td>\n",
       "      <td>3236.245003</td>\n",
       "      <td>3227.441671</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1266.150024</td>\n",
       "      <td>1269.449951</td>\n",
       "      <td>1262.199951</td>\n",
       "      <td>1265.050049</td>\n",
       "      <td>7455</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>3.291383</td>\n",
       "      <td>1271.731478</td>\n",
       "      <td>1252.638530</td>\n",
       "      <td>61.074894</td>\n",
       "      <td>89.119652</td>\n",
       "      <td>17.176047</td>\n",
       "      <td>1259.620003</td>\n",
       "      <td>1256.490835</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>12427.200200</td>\n",
       "      <td>12460.000000</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>346</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>12.589037</td>\n",
       "      <td>12412.230480</td>\n",
       "      <td>12335.739450</td>\n",
       "      <td>55.121774</td>\n",
       "      <td>182.692533</td>\n",
       "      <td>46.939163</td>\n",
       "      <td>12359.558270</td>\n",
       "      <td>12362.732490</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1947.449951</td>\n",
       "      <td>1933.500000</td>\n",
       "      <td>1946.650024</td>\n",
       "      <td>2017</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>6.185544</td>\n",
       "      <td>1937.594372</td>\n",
       "      <td>1896.865637</td>\n",
       "      <td>75.552570</td>\n",
       "      <td>301.805853</td>\n",
       "      <td>60.999199</td>\n",
       "      <td>1915.625000</td>\n",
       "      <td>1912.027500</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>7619.350098</td>\n",
       "      <td>7626.700195</td>\n",
       "      <td>7606.549805</td>\n",
       "      <td>7609.450195</td>\n",
       "      <td>811</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>5.184029</td>\n",
       "      <td>7634.889583</td>\n",
       "      <td>7581.715398</td>\n",
       "      <td>52.200986</td>\n",
       "      <td>51.249181</td>\n",
       "      <td>2.922274</td>\n",
       "      <td>7608.251660</td>\n",
       "      <td>7603.052515</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date          open          high           low  \\\n",
       "0  2024-09-26 09:15:00+05:30   3250.000000   3262.199951   3244.149902   \n",
       "1  2024-09-26 09:15:00+05:30   1266.150024   1269.449951   1262.199951   \n",
       "2  2024-09-26 09:15:00+05:30  12427.200200  12460.000000  12396.400390   \n",
       "3  2024-09-26 09:15:00+05:30   1940.300049   1947.449951   1933.500000   \n",
       "4  2024-09-26 09:15:00+05:30   7619.350098   7626.700195   7606.549805   \n",
       "\n",
       "          close  volume            tic       macd       boll_ub       boll_lb  \\\n",
       "0   3260.850098    1336  ASIANPAINT.BO   5.693770   3253.649352   3224.380653   \n",
       "1   1265.050049    7455    AXISBANK.BO   3.291383   1271.731478   1252.638530   \n",
       "2  12396.400390     346  BAJAJ-AUTO.BO  12.589037  12412.230480  12335.739450   \n",
       "3   1946.650024    2017  BAJAJFINSV.BO   6.185544   1937.594372   1896.865637   \n",
       "4   7609.450195     811  BAJFINANCE.BO   5.184029   7634.889583   7581.715398   \n",
       "\n",
       "      rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  63.582353  266.933037  47.135347   3236.245003   3227.441671  365.729838  \n",
       "1  61.074894   89.119652  17.176047   1259.620003   1256.490835  365.729838  \n",
       "2  55.121774  182.692533  46.939163  12359.558270  12362.732490  365.729838  \n",
       "3  75.552570  301.805853  60.999199   1915.625000   1912.027500  365.729838  \n",
       "4  52.200986   51.249181   2.922274   7608.251660   7603.052515  365.729838  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c0ed18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fadb1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['transformed_index'] = train.groupby('date').ngroup()\n",
    "\n",
    "# # Set transformed index as the new DataFrame index if needed\n",
    "# train.set_index('transformed_index', drop=True,inplace=True)\n",
    "# train.index.name = None\n",
    "# print(train)\n",
    "\n",
    "trade['transformed_index'] = trade.groupby('date').ngroup()\n",
    "\n",
    "# Set transformed index as the new DataFrame index if needed\n",
    "trade.set_index('transformed_index', drop=True,inplace=True)\n",
    "trade.index.name = None\n",
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67d9003b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3262.199951</td>\n",
       "      <td>3244.149902</td>\n",
       "      <td>3260.850098</td>\n",
       "      <td>1336</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>5.693770</td>\n",
       "      <td>3253.649352</td>\n",
       "      <td>3224.380653</td>\n",
       "      <td>63.582353</td>\n",
       "      <td>266.933037</td>\n",
       "      <td>47.135347</td>\n",
       "      <td>3236.245003</td>\n",
       "      <td>3227.441671</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1266.150024</td>\n",
       "      <td>1269.449951</td>\n",
       "      <td>1262.199951</td>\n",
       "      <td>1265.050049</td>\n",
       "      <td>7455</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>3.291383</td>\n",
       "      <td>1271.731478</td>\n",
       "      <td>1252.638530</td>\n",
       "      <td>61.074894</td>\n",
       "      <td>89.119652</td>\n",
       "      <td>17.176047</td>\n",
       "      <td>1259.620003</td>\n",
       "      <td>1256.490835</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>12427.200200</td>\n",
       "      <td>12460.000000</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>346</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>12.589037</td>\n",
       "      <td>12412.230480</td>\n",
       "      <td>12335.739450</td>\n",
       "      <td>55.121774</td>\n",
       "      <td>182.692533</td>\n",
       "      <td>46.939163</td>\n",
       "      <td>12359.558270</td>\n",
       "      <td>12362.732490</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1947.449951</td>\n",
       "      <td>1933.500000</td>\n",
       "      <td>1946.650024</td>\n",
       "      <td>2017</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>6.185544</td>\n",
       "      <td>1937.594372</td>\n",
       "      <td>1896.865637</td>\n",
       "      <td>75.552570</td>\n",
       "      <td>301.805853</td>\n",
       "      <td>60.999199</td>\n",
       "      <td>1915.625000</td>\n",
       "      <td>1912.027500</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>7619.350098</td>\n",
       "      <td>7626.700195</td>\n",
       "      <td>7606.549805</td>\n",
       "      <td>7609.450195</td>\n",
       "      <td>811</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>5.184029</td>\n",
       "      <td>7634.889583</td>\n",
       "      <td>7581.715398</td>\n",
       "      <td>52.200986</td>\n",
       "      <td>51.249181</td>\n",
       "      <td>2.922274</td>\n",
       "      <td>7608.251660</td>\n",
       "      <td>7603.052515</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date          open          high           low  \\\n",
       "1592  2024-09-26 09:15:00+05:30   3250.000000   3262.199951   3244.149902   \n",
       "1592  2024-09-26 09:15:00+05:30   1266.150024   1269.449951   1262.199951   \n",
       "1592  2024-09-26 09:15:00+05:30  12427.200200  12460.000000  12396.400390   \n",
       "1592  2024-09-26 09:15:00+05:30   1940.300049   1947.449951   1933.500000   \n",
       "1592  2024-09-26 09:15:00+05:30   7619.350098   7626.700195   7606.549805   \n",
       "\n",
       "             close  volume            tic       macd       boll_ub  \\\n",
       "1592   3260.850098    1336  ASIANPAINT.BO   5.693770   3253.649352   \n",
       "1592   1265.050049    7455    AXISBANK.BO   3.291383   1271.731478   \n",
       "1592  12396.400390     346  BAJAJ-AUTO.BO  12.589037  12412.230480   \n",
       "1592   1946.650024    2017  BAJAJFINSV.BO   6.185544   1937.594372   \n",
       "1592   7609.450195     811  BAJFINANCE.BO   5.184029   7634.889583   \n",
       "\n",
       "           boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "1592   3224.380653  63.582353  266.933037  47.135347   3236.245003   \n",
       "1592   1252.638530  61.074894   89.119652  17.176047   1259.620003   \n",
       "1592  12335.739450  55.121774  182.692533  46.939163  12359.558270   \n",
       "1592   1896.865637  75.552570  301.805853  60.999199   1915.625000   \n",
       "1592   7581.715398  52.200986   51.249181   2.922274   7608.251660   \n",
       "\n",
       "      close_60_sma  turbulence  \n",
       "1592   3227.441671  365.729838  \n",
       "1592   1256.490835  365.729838  \n",
       "1592  12362.732490  365.729838  \n",
       "1592   1912.027500  365.729838  \n",
       "1592   7603.052515  365.729838  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a81bdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade.to_csv('tradelala.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dac6e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"trainlala.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "13d51024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>3262.199951</td>\n",
       "      <td>3244.149902</td>\n",
       "      <td>3260.850098</td>\n",
       "      <td>1336</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>5.693770</td>\n",
       "      <td>3253.649352</td>\n",
       "      <td>3224.380653</td>\n",
       "      <td>63.582353</td>\n",
       "      <td>266.933037</td>\n",
       "      <td>47.135347</td>\n",
       "      <td>3236.245003</td>\n",
       "      <td>3227.441671</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1266.150024</td>\n",
       "      <td>1269.449951</td>\n",
       "      <td>1262.199951</td>\n",
       "      <td>1265.050049</td>\n",
       "      <td>7455</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>3.291383</td>\n",
       "      <td>1271.731478</td>\n",
       "      <td>1252.638530</td>\n",
       "      <td>61.074894</td>\n",
       "      <td>89.119652</td>\n",
       "      <td>17.176047</td>\n",
       "      <td>1259.620003</td>\n",
       "      <td>1256.490835</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>12427.200200</td>\n",
       "      <td>12460.000000</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>12396.400390</td>\n",
       "      <td>346</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>12.589037</td>\n",
       "      <td>12412.230480</td>\n",
       "      <td>12335.739450</td>\n",
       "      <td>55.121774</td>\n",
       "      <td>182.692533</td>\n",
       "      <td>46.939163</td>\n",
       "      <td>12359.558270</td>\n",
       "      <td>12362.732490</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>1940.300049</td>\n",
       "      <td>1947.449951</td>\n",
       "      <td>1933.500000</td>\n",
       "      <td>1946.650024</td>\n",
       "      <td>2017</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>6.185544</td>\n",
       "      <td>1937.594372</td>\n",
       "      <td>1896.865637</td>\n",
       "      <td>75.552570</td>\n",
       "      <td>301.805853</td>\n",
       "      <td>60.999199</td>\n",
       "      <td>1915.625000</td>\n",
       "      <td>1912.027500</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-26 09:15:00+05:30</td>\n",
       "      <td>7619.350098</td>\n",
       "      <td>7626.700195</td>\n",
       "      <td>7606.549805</td>\n",
       "      <td>7609.450195</td>\n",
       "      <td>811</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>5.184029</td>\n",
       "      <td>7634.889583</td>\n",
       "      <td>7581.715398</td>\n",
       "      <td>52.200986</td>\n",
       "      <td>51.249181</td>\n",
       "      <td>2.922274</td>\n",
       "      <td>7608.251660</td>\n",
       "      <td>7603.052515</td>\n",
       "      <td>365.729838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date          open          high           low  \\\n",
       "0  2024-09-26 09:15:00+05:30   3250.000000   3262.199951   3244.149902   \n",
       "1  2024-09-26 09:15:00+05:30   1266.150024   1269.449951   1262.199951   \n",
       "2  2024-09-26 09:15:00+05:30  12427.200200  12460.000000  12396.400390   \n",
       "3  2024-09-26 09:15:00+05:30   1940.300049   1947.449951   1933.500000   \n",
       "4  2024-09-26 09:15:00+05:30   7619.350098   7626.700195   7606.549805   \n",
       "\n",
       "          close  volume            tic       macd       boll_ub       boll_lb  \\\n",
       "0   3260.850098    1336  ASIANPAINT.BO   5.693770   3253.649352   3224.380653   \n",
       "1   1265.050049    7455    AXISBANK.BO   3.291383   1271.731478   1252.638530   \n",
       "2  12396.400390     346  BAJAJ-AUTO.BO  12.589037  12412.230480  12335.739450   \n",
       "3   1946.650024    2017  BAJAJFINSV.BO   6.185544   1937.594372   1896.865637   \n",
       "4   7609.450195     811  BAJFINANCE.BO   5.184029   7634.889583   7581.715398   \n",
       "\n",
       "      rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  63.582353  266.933037  47.135347   3236.245003   3227.441671  365.729838  \n",
       "1  61.074894   89.119652  17.176047   1259.620003   1256.490835  365.729838  \n",
       "2  55.121774  182.692533  46.939163  12359.558270  12362.732490  365.729838  \n",
       "3  75.552570  301.805853  60.999199   1915.625000   1912.027500  365.729838  \n",
       "4  52.200986   51.249181   2.922274   7608.251660   7603.052515  365.729838  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28d66621-48cf-40ea-b98d-5b262d41fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69240\n",
      "69240\n"
     ]
    }
   ],
   "source": [
    "# train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "# trade = data_split(df, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5484b-52c9-41ed-aa33-f6aa953ac261",
   "metadata": {},
   "source": [
    "### 5. Construction of Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c6cce40-87e6-410c-ac31-d555f17adaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TradingEnv import StockTradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b7c5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.config import INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db88fde3-3088-471d-a275-f30f1c22f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "490ac2e0-422b-4f0d-9d59-c7a13738bb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-26 09:15:00+05:30</td>\n",
       "      <td>3160.000000</td>\n",
       "      <td>3164.949951</td>\n",
       "      <td>3144.600098</td>\n",
       "      <td>3144.600098</td>\n",
       "      <td>1149</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>-3.100598</td>\n",
       "      <td>3168.335605</td>\n",
       "      <td>3147.549380</td>\n",
       "      <td>38.554848</td>\n",
       "      <td>-185.609583</td>\n",
       "      <td>15.263966</td>\n",
       "      <td>3158.422405</td>\n",
       "      <td>3161.633048</td>\n",
       "      <td>1018.954971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-26 09:15:00+05:30</td>\n",
       "      <td>1169.400024</td>\n",
       "      <td>1172.500000</td>\n",
       "      <td>1166.949951</td>\n",
       "      <td>1172.099976</td>\n",
       "      <td>14169</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>-0.461603</td>\n",
       "      <td>1171.318389</td>\n",
       "      <td>1164.286616</td>\n",
       "      <td>55.705405</td>\n",
       "      <td>89.148906</td>\n",
       "      <td>13.975060</td>\n",
       "      <td>1168.573336</td>\n",
       "      <td>1169.387286</td>\n",
       "      <td>1018.954971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-26 09:15:00+05:30</td>\n",
       "      <td>10390.400390</td>\n",
       "      <td>10492.000000</td>\n",
       "      <td>10336.599610</td>\n",
       "      <td>10492.000000</td>\n",
       "      <td>968</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>28.281197</td>\n",
       "      <td>10451.073820</td>\n",
       "      <td>10326.471300</td>\n",
       "      <td>69.437647</td>\n",
       "      <td>203.898645</td>\n",
       "      <td>51.196030</td>\n",
       "      <td>10373.015040</td>\n",
       "      <td>10312.927540</td>\n",
       "      <td>1018.954971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-26 09:15:00+05:30</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1651.500000</td>\n",
       "      <td>1642.949951</td>\n",
       "      <td>1643.900024</td>\n",
       "      <td>1830</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>2.261813</td>\n",
       "      <td>1643.801025</td>\n",
       "      <td>1630.268957</td>\n",
       "      <td>66.122814</td>\n",
       "      <td>242.847447</td>\n",
       "      <td>70.504370</td>\n",
       "      <td>1635.731661</td>\n",
       "      <td>1634.464164</td>\n",
       "      <td>1018.954971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-26 09:15:00+05:30</td>\n",
       "      <td>6758.799805</td>\n",
       "      <td>6774.000000</td>\n",
       "      <td>6753.299805</td>\n",
       "      <td>6768.250000</td>\n",
       "      <td>440</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>-0.942347</td>\n",
       "      <td>6767.529586</td>\n",
       "      <td>6727.705326</td>\n",
       "      <td>59.941815</td>\n",
       "      <td>197.308194</td>\n",
       "      <td>39.900623</td>\n",
       "      <td>6748.049967</td>\n",
       "      <td>6742.945833</td>\n",
       "      <td>1018.954971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date           tic          open          high  \\\n",
       "0  2024-08-26 09:15:00+05:30   3160.000000   3164.949951   3144.600098   \n",
       "0  2024-08-26 09:15:00+05:30   1169.400024   1172.500000   1166.949951   \n",
       "0  2024-08-26 09:15:00+05:30  10390.400390  10492.000000  10336.599610   \n",
       "0  2024-08-26 09:15:00+05:30   1650.000000   1651.500000   1642.949951   \n",
       "0  2024-08-26 09:15:00+05:30   6758.799805   6774.000000   6753.299805   \n",
       "\n",
       "            low  close         volume       macd       boll_ub       boll_lb  \\\n",
       "0   3144.600098   1149  ASIANPAINT.BO  -3.100598   3168.335605   3147.549380   \n",
       "0   1172.099976  14169    AXISBANK.BO  -0.461603   1171.318389   1164.286616   \n",
       "0  10492.000000    968  BAJAJ-AUTO.BO  28.281197  10451.073820  10326.471300   \n",
       "0   1643.900024   1830  BAJAJFINSV.BO   2.261813   1643.801025   1630.268957   \n",
       "0   6768.250000    440  BAJFINANCE.BO  -0.942347   6767.529586   6727.705326   \n",
       "\n",
       "      rsi_30      cci_30      dx_30  close_30_sma  close_60_sma   turbulence  \n",
       "0  38.554848 -185.609583  15.263966   3158.422405   3161.633048  1018.954971  \n",
       "0  55.705405   89.148906  13.975060   1168.573336   1169.387286  1018.954971  \n",
       "0  69.437647  203.898645  51.196030  10373.015040  10312.927540  1018.954971  \n",
       "0  66.122814  242.847447  70.504370   1635.731661   1634.464164  1018.954971  \n",
       "0  59.941815  197.308194  39.900623   6748.049967   6742.945833  1018.954971  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96cf6369-0195-453c-be44-674a48ac5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"min_portfolio_value\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd613e04-ff28-40c4-8eba-fa0fcafdb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da8507ba-f46f-43df-bc16-9ad39026c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = False\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7d88eb5-3fdf-4d97-87e6-6fac63e83859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from stable_baselines3.common.logger import configure\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01cfb65-c9c6-4920-a99e-4fb4cb34451b",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90aaf254-10a4-427b-87d0-a51677ae73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81600ba0-a53e-4def-9010-6fd138f496a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 5             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | -0.745        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -11.1         |\n",
      "|    reward             | -0.0064009377 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.0675        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 4.56        |\n",
      "|    reward             | 0.012223659 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.0147      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 6.84         |\n",
      "|    reward             | -0.018406237 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.033        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.412       |\n",
      "|    reward             | 0.0012800539 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00736      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45         |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 9.32        |\n",
      "|    reward             | 0.008479993 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0466      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -2.18       |\n",
      "|    reward             | 0.041035924 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00395     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.358        |\n",
      "|    reward             | -0.005036614 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00737      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -4.52      |\n",
      "|    reward             | 0.05549253 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.0125     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 4.18         |\n",
      "|    reward             | -0.014078458 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -7.94       |\n",
      "|    reward             | -0.10764785 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.0417      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.6        |\n",
      "|    explained_variance | -8.61        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.418        |\n",
      "|    reward             | -0.009204999 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 0.000818     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 23.9        |\n",
      "|    reward             | -0.04586871 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 2.47        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -48.6      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.06716073 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.101      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 7.71        |\n",
      "|    reward             | -0.25594947 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.0331      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 117       |\n",
      "|    reward             | -4.011546 |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 5.75      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -2.58        |\n",
      "|    reward             | -0.030727591 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.00423      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 0.14       |\n",
      "|    reward             | 0.20503728 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 0.00238    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 4.25        |\n",
      "|    reward             | -0.02778498 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.00759     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.166       |\n",
      "|    reward             | -0.014290922 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 0.000462     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -1.64        |\n",
      "|    reward             | -0.059571613 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -0.376      |\n",
      "|    reward             | 0.015343192 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -2.38       |\n",
      "|    reward             | -0.03359606 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 0.00402     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.5        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -5.94        |\n",
      "|    reward             | -0.047529228 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.0237       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 10.7        |\n",
      "|    reward             | -0.07019722 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 0.0607      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 9.29        |\n",
      "|    reward             | 0.076753385 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.033       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | 0.799        |\n",
      "|    reward             | -0.025605004 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 0.00828      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -24.7      |\n",
      "|    reward             | 0.17791332 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 0.258      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | -2.23       |\n",
      "|    reward             | -0.12320775 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 0.00434     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -4.12       |\n",
      "|    reward             | -0.05146787 |\n",
      "|    std                | 1.49        |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -55        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.10846061 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 0.00152    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -2.91       |\n",
      "|    reward             | 0.056216266 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 0.00418     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.7       |\n",
      "|    explained_variance | 0.0212      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -6.58       |\n",
      "|    reward             | 0.013651225 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | -0.621       |\n",
      "|    reward             | -0.044994634 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 0.00232      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -9.99       |\n",
      "|    reward             | -0.08738618 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 0.0331      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.6       |\n",
      "|    explained_variance | 0.053       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -29.9       |\n",
      "|    reward             | -0.12513493 |\n",
      "|    std                | 1.6         |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -56.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -4.31      |\n",
      "|    reward             | -0.0344218 |\n",
      "|    std                | 1.61       |\n",
      "|    value_loss         | 0.023      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | -248        |\n",
      "|    reward             | -0.04272398 |\n",
      "|    std                | 1.62        |\n",
      "|    value_loss         | 33.3        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -22.7       |\n",
      "|    reward             | -0.08302008 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 1.18        |\n",
      "|    reward             | 0.050774854 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.00758     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -57.9      |\n",
      "|    explained_variance | 0.137      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | 0.07268173 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 0.00152    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -58.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 6.68       |\n",
      "|    reward             | 0.22721753 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.0221     |\n",
      "--------------------------------------\n",
      "day: 2307, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 945657.65\n",
      "total_reward: -54342.35\n",
      "total_cost: 11591.58\n",
      "total_trades: 34636\n",
      "Sharpe: 0.381\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 2.89         |\n",
      "|    reward             | -0.038645368 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 0.00541      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -58.8       |\n",
      "|    explained_variance | -0.00226    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 3.38        |\n",
      "|    reward             | 0.036764268 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 0.00663     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 7.58        |\n",
      "|    reward             | -0.02498146 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -59.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -7.15      |\n",
      "|    reward             | 0.39839518 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 0.0287     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -5.06       |\n",
      "|    reward             | 0.085646376 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 0.00965     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 3.8          |\n",
      "|    reward             | -0.008755834 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 0.00678      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.2        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -7.01        |\n",
      "|    reward             | -0.050818894 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 0.0158       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -60.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -0.722     |\n",
      "|    reward             | 0.22770244 |\n",
      "|    std                | 1.82       |\n",
      "|    value_loss         | 0.000534   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -2.8        |\n",
      "|    reward             | 0.041829478 |\n",
      "|    std                | 1.84        |\n",
      "|    value_loss         | 0.00478     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 277          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 7.47         |\n",
      "|    reward             | -0.069279805 |\n",
      "|    std                | 1.87         |\n",
      "|    value_loss         | 0.0144       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -2.24       |\n",
      "|    reward             | 0.009218805 |\n",
      "|    std                | 1.89        |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | -1.32       |\n",
      "|    reward             | -0.06705671 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 0.000974    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 6.27       |\n",
      "|    reward             | 0.14966498 |\n",
      "|    std                | 1.92       |\n",
      "|    value_loss         | 0.0245     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 9.15       |\n",
      "|    reward             | 0.31891644 |\n",
      "|    std                | 1.94       |\n",
      "|    value_loss         | 0.048      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 5.71       |\n",
      "|    reward             | -0.0871105 |\n",
      "|    std                | 1.95       |\n",
      "|    value_loss         | 0.00973    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 309        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -12.6      |\n",
      "|    reward             | 0.06689132 |\n",
      "|    std                | 1.97       |\n",
      "|    value_loss         | 0.0584     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -63.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 0.34       |\n",
      "|    reward             | 0.05504995 |\n",
      "|    std                | 1.99       |\n",
      "|    value_loss         | 0.00697    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 321        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -63.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -6.26      |\n",
      "|    reward             | 0.12276658 |\n",
      "|    std                | 2.01       |\n",
      "|    value_loss         | 0.0143     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -63.7      |\n",
      "|    explained_variance | -0.000157  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 195        |\n",
      "|    reward             | 0.10490094 |\n",
      "|    std                | 2.03       |\n",
      "|    value_loss         | 61.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 333        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -64        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 6.96       |\n",
      "|    reward             | 0.04250094 |\n",
      "|    std                | 2.05       |\n",
      "|    value_loss         | 0.0139     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | -31.4       |\n",
      "|    reward             | 0.055965897 |\n",
      "|    std                | 2.06        |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 22.9        |\n",
      "|    reward             | 0.093726136 |\n",
      "|    std                | 2.08        |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -20.5        |\n",
      "|    reward             | -0.118433714 |\n",
      "|    std                | 2.09         |\n",
      "|    value_loss         | 0.116        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.679      |\n",
      "|    reward             | -0.02750874 |\n",
      "|    std                | 2.11        |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 12.6        |\n",
      "|    reward             | -0.13246356 |\n",
      "|    std                | 2.13        |\n",
      "|    value_loss         | 0.0433      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -3.9        |\n",
      "|    reward             | 0.004544515 |\n",
      "|    std                | 2.15        |\n",
      "|    value_loss         | 0.00971     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | 2.71        |\n",
      "|    reward             | 0.009210757 |\n",
      "|    std                | 2.16        |\n",
      "|    value_loss         | 0.00639     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 376        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -65.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -10.6      |\n",
      "|    reward             | -0.5701777 |\n",
      "|    std                | 2.18       |\n",
      "|    value_loss         | 0.0561     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 381        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -66.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -21.9      |\n",
      "|    reward             | 0.29723752 |\n",
      "|    std                | 2.2        |\n",
      "|    value_loss         | 0.122      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 387         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -6.83       |\n",
      "|    reward             | 0.093732506 |\n",
      "|    std                | 2.22        |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -6.33        |\n",
      "|    reward             | -0.022421258 |\n",
      "|    std                | 2.24         |\n",
      "|    value_loss         | 0.0156       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 398         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 180         |\n",
      "|    reward             | -0.11162369 |\n",
      "|    std                | 2.25        |\n",
      "|    value_loss         | 7.58        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 19           |\n",
      "|    reward             | -0.014535611 |\n",
      "|    std                | 2.27         |\n",
      "|    value_loss         | 0.0827       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | 6.54        |\n",
      "|    reward             | -0.11468745 |\n",
      "|    std                | 2.29        |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 414        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -67.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -19.4      |\n",
      "|    reward             | 0.14517753 |\n",
      "|    std                | 2.32       |\n",
      "|    value_loss         | 0.103      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 419       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 9.12      |\n",
      "|    reward             | 0.1978224 |\n",
      "|    std                | 2.34      |\n",
      "|    value_loss         | 0.0485    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.1        |\n",
      "|    explained_variance | 0.0557       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 34.2         |\n",
      "|    reward             | -0.005138697 |\n",
      "|    std                | 2.35         |\n",
      "|    value_loss         | 0.276        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 430        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -68.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 6.06       |\n",
      "|    reward             | 0.14483574 |\n",
      "|    std                | 2.36       |\n",
      "|    value_loss         | 0.023      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 436         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -0.483      |\n",
      "|    reward             | 0.031607714 |\n",
      "|    std                | 2.4         |\n",
      "|    value_loss         | 0.037       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.202       |\n",
      "|    reward             | 0.015587459 |\n",
      "|    std                | 2.42        |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 448        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -69.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 5.98       |\n",
      "|    reward             | -22.383034 |\n",
      "|    std                | 2.44       |\n",
      "|    value_loss         | 0.00917    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 454        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -69.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | -3.68      |\n",
      "|    reward             | 0.23570727 |\n",
      "|    std                | 2.47       |\n",
      "|    value_loss         | 0.0138     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 459        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -70        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -3.87      |\n",
      "|    reward             | -0.2442028 |\n",
      "|    std                | 2.5        |\n",
      "|    value_loss         | 0.00403    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 465          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | -19.5        |\n",
      "|    reward             | -0.039951514 |\n",
      "|    std                | 2.52         |\n",
      "|    value_loss         | 0.0828       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 470        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -70.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -21.7      |\n",
      "|    reward             | -30.912647 |\n",
      "|    std                | 2.54       |\n",
      "|    value_loss         | 0.107      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 475       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -11.6     |\n",
      "|    reward             | 0.2083058 |\n",
      "|    std                | 2.56      |\n",
      "|    value_loss         | 0.0333    |\n",
      "-------------------------------------\n",
      "day: 2307, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1139262.88\n",
      "total_reward: 139262.88\n",
      "total_cost: 15640.14\n",
      "total_trades: 40051\n",
      "Sharpe: 0.310\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 481       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 4.72      |\n",
      "|    reward             | 0.1445529 |\n",
      "|    std                | 2.58      |\n",
      "|    value_loss         | 0.0184    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 487        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -71.3      |\n",
      "|    explained_variance | 0.0927     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 1.02       |\n",
      "|    reward             | -2.9435575 |\n",
      "|    std                | 2.61       |\n",
      "|    value_loss         | 0.00346    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 0.928       |\n",
      "|    reward             | -0.23298645 |\n",
      "|    std                | 2.63        |\n",
      "|    value_loss         | 0.0223      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 501         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -10.2       |\n",
      "|    reward             | -0.09365286 |\n",
      "|    std                | 2.65        |\n",
      "|    value_loss         | 0.0414      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 507        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -71.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -6.32      |\n",
      "|    reward             | 0.08678514 |\n",
      "|    std                | 2.66       |\n",
      "|    value_loss         | 0.0127     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 513        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | 0.09681257 |\n",
      "|    std                | 2.68       |\n",
      "|    value_loss         | 0.011      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 518        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.21798109 |\n",
      "|    std                | 2.7        |\n",
      "|    value_loss         | 0.0921     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 524        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 4.59       |\n",
      "|    reward             | -0.2099686 |\n",
      "|    std                | 2.72       |\n",
      "|    value_loss         | 0.00779    |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 530      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.7    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 33.3     |\n",
      "|    reward             | 0.06148  |\n",
      "|    std                | 2.74     |\n",
      "|    value_loss         | 0.225    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 536        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 22.7       |\n",
      "|    reward             | 0.30860648 |\n",
      "|    std                | 2.76       |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 542        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 10.5       |\n",
      "|    reward             | 0.09545774 |\n",
      "|    std                | 2.79       |\n",
      "|    value_loss         | 0.0271     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 548        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 9.02       |\n",
      "|    reward             | 0.10850439 |\n",
      "|    std                | 2.83       |\n",
      "|    value_loss         | 0.0204     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 554          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 6.24         |\n",
      "|    reward             | 0.0070052654 |\n",
      "|    std                | 2.85         |\n",
      "|    value_loss         | 0.00878      |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3c468e6-ae7d-42a0-af6f-c0a6e7f3d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c_intraday\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02b3a6-d4ad-4135-bb40-319f9364962e",
   "metadata": {},
   "source": [
    "### Testing A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16bbad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>3026.600098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>323</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>3028.350098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1159.599976</td>\n",
       "      <td>1163.550049</td>\n",
       "      <td>1156.750000</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>4737</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>1162.949951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9775.299805</td>\n",
       "      <td>9740.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>105</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>9770.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>1535.900024</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>1535.199951</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1689</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>1538.400024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-16 09:15:00+05:30</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6509.299805</td>\n",
       "      <td>6472.450195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>1716</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3054.287317</td>\n",
       "      <td>3015.962683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>6487.700195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date         open         high          low  \\\n",
       "0  2024-08-16 09:15:00+05:30  3056.000000  3056.000000  3026.600098   \n",
       "0  2024-08-16 09:15:00+05:30  1159.599976  1163.550049  1156.750000   \n",
       "0  2024-08-16 09:15:00+05:30  9770.000000  9775.299805  9740.000000   \n",
       "0  2024-08-16 09:15:00+05:30  1535.900024  1539.900024  1535.199951   \n",
       "0  2024-08-16 09:15:00+05:30  6509.299805  6509.299805  6472.450195   \n",
       "\n",
       "         close  volume            tic  macd      boll_ub      boll_lb  rsi_30  \\\n",
       "0  3028.350098     323  ASIANPAINT.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "0  1162.949951    4737    AXISBANK.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "0  9770.000000     105  BAJAJ-AUTO.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "0  1538.400024    1689  BAJAJFINSV.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "0  6487.700195    1716  BAJFINANCE.BO   0.0  3054.287317  3015.962683   100.0   \n",
       "\n",
       "      cci_30  dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  66.666667  100.0   3028.350098   3028.350098         0.0  \n",
       "0  66.666667  100.0   1162.949951   1162.949951         0.0  \n",
       "0  66.666667  100.0   9770.000000   9770.000000         0.0  \n",
       "0  66.666667  100.0   1538.400024   1538.400024         0.0  \n",
       "0  66.666667  100.0   6487.700195   6487.700195         0.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b36e7bc5-7e93-409f-9573-3c3f01cba845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "trained_a2c = A2C.load(\"trained_models/agent_a2c_intraday\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08afc9c2-5823-4afb-909a-7a9ab0622662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4ad41c5-5076-4f57-bbc2-6649285e78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"min_portfolio_value\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "250d6844-a243-4255-9abf-7eb6a471cbaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m e_trade_gym \u001b[38;5;241m=\u001b[39m StockTradingEnv(df \u001b[38;5;241m=\u001b[39m trade, turbulence_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m      2\u001b[0m env_trade, obs_trade \u001b[38;5;241m=\u001b[39m e_trade_gym\u001b[38;5;241m.\u001b[39mget_sb_env()\n",
      "File \u001b[1;32mc:\\Users\\Utkarsh Jain\\Reinforcement-Learning-tools-for-Auto-Stock-Trading-main\\TradingEnv.py:77\u001b[0m, in \u001b[0;36mStockTradingEnv.__init__\u001b[1;34m(self, df, stock_dim, hmax, initial_amount, num_stock_shares, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, min_portfolio_value, tech_indicator_list, turbulence_threshold, risk_indicator_col, make_plots, print_verbosity, day, initial, previous_state, model_name, mode, iteration)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m=\u001b[39m iteration\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# initalize state\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# initialize reward\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Utkarsh Jain\\Reinforcement-Learning-tools-for-Auto-Stock-Trading-main\\TradingEnv.py:416\u001b[0m, in \u001b[0;36mStockTradingEnv._initiate_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# For Initial State\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mtic\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;66;03m# for multiple stock\u001b[39;00m\n\u001b[0;32m    414\u001b[0m         state \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    415\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_amount]\n\u001b[1;32m--> 416\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    417\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_stock_shares\n\u001b[0;32m    418\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[0;32m    419\u001b[0m                 (\n\u001b[0;32m    420\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[tech]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    421\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m tech \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtech_indicator_list\n\u001b[0;32m    422\u001b[0m                 ),\n\u001b[0;32m    423\u001b[0m                 [],\n\u001b[0;32m    424\u001b[0m             )\n\u001b[0;32m    425\u001b[0m         )  \u001b[38;5;66;03m# append initial stocks_share to initial state, instead of all zero\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;66;03m# for single stock\u001b[39;00m\n\u001b[0;32m    428\u001b[0m         state \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    429\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_amount]\n\u001b[0;32m    430\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclose]\n\u001b[0;32m    431\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_dim\n\u001b[0;32m    432\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[tech]] \u001b[38;5;28;01mfor\u001b[39;00m tech \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtech_indicator_list), [])\n\u001b[0;32m    433\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01104517-6131-43b1-aaf8-ac8fcd62f62e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (571,) into shape (301,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_account_value_a2c, df_actions_a2c \u001b[38;5;241m=\u001b[39m \u001b[43mDRLAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRL_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrained_a2c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43me_trade_gym\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m if_using_a2c \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\finrl\\agents\\stablebaselines3\\models.py:139\u001b[0m, in \u001b[0;36mDRLAgent.DRL_prediction\u001b[1;34m(model, environment, deterministic)\u001b[0m\n\u001b[0;32m    136\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_obs, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# account_memory = test_env.env_method(method_name=\"save_asset_memory\")\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# actions_memory = test_env.env_method(method_name=\"save_action_memory\")\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m test_obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m \u001b[43mtest_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    142\u001b[0m     i \u001b[38;5;241m==\u001b[39m max_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    143\u001b[0m ):  \u001b[38;5;66;03m# more descriptive condition for early termination to clarify the logic\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     account_memory \u001b[38;5;241m=\u001b[39m test_env\u001b[38;5;241m.\u001b[39menv_method(method_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_asset_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:71\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m     70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:108\u001b[0m, in \u001b[0;36mDummyVecEnv._save_obs\u001b[1;34m(self, env_idx, obs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs[key][env_idx] \u001b[38;5;241m=\u001b[39m obs[key]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (571,) into shape (301,)"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d4354a4-3de3-4773-b7f3-9204c8f8bb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-01 09:15:00+05:30</td>\n",
       "      <td>1.000879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-10-03 09:15:00+05:30</td>\n",
       "      <td>1.000879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-10-04 09:15:00+05:30</td>\n",
       "      <td>1.000879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-07 09:15:00+05:30</td>\n",
       "      <td>1.000879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-10-08 09:15:00+05:30</td>\n",
       "      <td>1.000879e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  account_value\n",
       "4  2024-10-01 09:15:00+05:30   1.000879e+06\n",
       "5  2024-10-03 09:15:00+05:30   1.000879e+06\n",
       "6  2024-10-04 09:15:00+05:30   1.000879e+06\n",
       "7  2024-10-07 09:15:00+05:30   1.000879e+06\n",
       "8  2024-10-08 09:15:00+05:30   1.000879e+06"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_a2c.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c673516-c782-44d4-8d3d-d541f5c16863",
   "metadata": {},
   "source": [
    "## DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "790dae9c-e814-4736-a083-0a223218e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ba864a4-5815-4fa1-a0e9-e2f54be94915",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f867d1e0-85e4-469d-a490-3d35ccd15c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(\"trained_models/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "231c819a-c423-4314-a3f5-3ad4c9e6aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65d19496-cbdd-4623-9a5b-8e4bf294c4f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tail'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_account_value_ddpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtail\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tail'"
     ]
    }
   ],
   "source": [
    "df_account_value_ddpg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4b2ad56-2037-45e2-a3a0-4f4e2dccf290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb5f57d-f632-482e-9feb-0f0482565f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 87        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 23        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 4.0592203 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018641617 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0099     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | -2.159677   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 93         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01949444 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00204   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    reward               | -0.4911504 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 62.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020603677 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0283      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -1.0691344  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023066852 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0518      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -3.1217067  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022772666 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -2.244483   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016262408 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 2.2637844   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021768956 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 1.1457258   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022010868 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.23370826  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02112437 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 138        |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 3.1912692  |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 83.8       |\n",
      "----------------------------------------\n",
      "day: 2584, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2548043.21\n",
      "total_reward: 1548043.21\n",
      "total_cost: 1816639.98\n",
      "total_trades: 62995\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019484561 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.8670269   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018757598 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 1.2204263   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02018834 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0897     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 0.49629197 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035004307 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.3765069   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016213335 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 521         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -1.3072859  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046311066 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 0.28919002  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027561057 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.320474    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020947075 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.424583   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020668086 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 0.033359185 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015869807 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.5187614   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 569         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028655048 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -2.9605656  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027514838 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -0.9957301  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3638944.54\n",
      "total_reward: 2638944.54\n",
      "total_cost: 1892322.70\n",
      "total_trades: 62950\n",
      "Sharpe: 0.342\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 485        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01757014 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.3       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    reward               | -3.1509938 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 208        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 506          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017601084  |\n",
      "|    clip_fraction        | 0.251        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.2         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | -0.061551515 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016975727 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.7874303   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025144424 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0789      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 5.1823115   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019621823 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 1.4977766   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966241 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 458         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.008677103 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968162 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 63.980614   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019533072 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0025      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -33.163105  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010356357 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 390         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 1.6961972   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339005 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00446     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.43e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | -0.68038285 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013459545 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.002246885 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009769364 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.47e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 8.783529    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 740         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023945 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 9.455886    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 893         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4962386.90\n",
      "total_reward: 3962386.90\n",
      "total_cost: 1628350.45\n",
      "total_trades: 60723\n",
      "Sharpe: 0.483\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020566382 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.00213     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 8.4830065   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 939         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022856992 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 716         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.75767094  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 662         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014955524 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -3.1039412  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018417671 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -1.1225958  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021088347 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    reward               | 0.102188066 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 869         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023542933 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 0.8827302   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 892        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01777952 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -0.6675529 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 55.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015703835 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0446      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 2.0703394   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 943        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0248465  |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.4       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    reward               | -20.330748 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 132        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 970         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008362107 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 611         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 3.0446172   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 94         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 997        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00456327 |\n",
      "|    clip_fraction        | 0.00903    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.0134     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.34e+03   |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.006     |\n",
      "|    reward               | 0.08670508 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 1.04e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012176418 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 931         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.6272429   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 18565041.83\n",
      "total_reward: 17565041.83\n",
      "total_cost: 1571922.15\n",
      "total_trades: 59438\n",
      "Sharpe: 0.434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010628522 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.12978487  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1080        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011880076 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.00865     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.1436437  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013677685 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -1.4845666  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1136        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014884111 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 1.2779398   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 5.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1163        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018967737 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 773         |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.7137463   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010445684 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0253      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.07e+03    |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -18.559805  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 7.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015584242 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 714         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 7.440749    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116675 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 590         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 18.989462   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125971 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.73e+03    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -1.4763755  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1299        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011986498 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.3607123   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1327        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012717884 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 43.014088   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.96e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012323972 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.63e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -16.608868  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.21e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 1383       |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01207923 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | 0.00549    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.38e+03   |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    reward               | -0.2527314 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.35e+04   |\n",
      "----------------------------------------\n",
      "day: 2584, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 26627953.54\n",
      "total_reward: 25627953.54\n",
      "total_cost: 1401550.80\n",
      "total_trades: 57925\n",
      "Sharpe: 0.477\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1410        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011564285 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+04    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.2492746  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1437        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012530673 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+04    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.3352162   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1464        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013804965 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+04    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 244.1249    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1491        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011457941 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.62e+03    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -10.248179  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1518        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026308667 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.00541     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+04    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 1.7162712   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1546        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020880006 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | -0.7976823  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1573         |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02241113   |\n",
      "|    clip_fraction        | 0.35         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.32e+03     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.031692922 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024806684 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 972         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.74611443 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 7.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1627        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038788136 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 3.6908529   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 86         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 1654       |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899603 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 315        |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.00846   |\n",
      "|    reward               | -5.1034603 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 2.71e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1681        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023305807 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.63258123  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 850         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1709        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012877064 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 0.2611612   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 7.56e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032109782 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -3.1880398  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3899965.03\n",
      "total_reward: 2899965.03\n",
      "total_cost: 996530.66\n",
      "total_trades: 53917\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017765256 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | -0.5529942  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1790        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555641 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | -0.41650042 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1817       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03277135 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.6       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    reward               | -1.915599  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029676326 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | -0.71904254 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020127747 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -0.69034123 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1898        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013476102 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 2.3798966   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759398 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 4.627062    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1953        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015066544 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -1.5916415  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017956853 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -0.8279543  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 2007        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015773416 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -2.0808382  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024384923 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 0.31988987  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 2064        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013274232 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -0.25219807 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2770992.74\n",
      "total_reward: 1770992.74\n",
      "total_cost: 449698.54\n",
      "total_trades: 48047\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 2091        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011096032 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -0.83965105 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 2118        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012155503 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.2267982   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 85.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 2145        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012608224 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.8338106   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 2173        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159353 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.21277303  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 2200        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016858857 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.7155553  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 93.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 2227         |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129864905 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | 0.17309016   |\n",
      "|    std                  | 1.18         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 2254        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014147153 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -3.0241158  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 490         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 2283        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023613347 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 0.7739482   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 2310        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015734915 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -0.6703647  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 2338        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013813818 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.4        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.21463184 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 2365        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015853245 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.71934575 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 2392        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013356132 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 1.4985831   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 82         |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 2419       |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01764878 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.4        |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    reward               | 1.1066265  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=200000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f1b6e13-9c3c-42a3-837e-9fed20675311",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(\"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc8368-a067-41da-a3c8-c01832ad8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c6817-687a-43eb-b61e-82b4133797b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99cbd1-137c-4b9d-89e8-7930d2554547",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bb4bd-1de7-4b63-b1a7-8075c240d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93902222-3672-46b2-b507-709d244a357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311428e-5efd-4687-a745-e4d63c46900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9775b9-851d-44c0-a54c-690f8c72b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b43d95-5126-4723-9a66-185401b80ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da0694-1230-40db-acf7-167680a0d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab2b83-c8d2-440f-8390-9d65ab4e05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe25012-e974-4ff5-8edf-b1c39737f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff242e-6727-4bf3-90aa-4686ed16682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fea52c-38db-42e6-ad48-a9acbece3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7eb9d-c7df-4d37-b9f4-66c9466e6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
