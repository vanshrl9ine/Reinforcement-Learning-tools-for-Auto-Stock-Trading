{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29853799-20a5-4196-b857-879d781aeb1b",
   "metadata": {},
   "source": [
    "# **_Reinforcement Learning tools for Auto-Stock Trading_**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd62e2e-2265-46d6-b8c6-d00b3214467f",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc5a494-5c1b-4cc0-83e5-efb4c18a4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Data Science Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a144855a-0f1b-4e2c-80a2-b2331979704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vansh\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\exchange_calendars\\exchange_calendar.py:2347: FutureWarning: 'T' is deprecated and will be removed in a future version. Please use 'min' instead of 'T'.\n",
      "  align: pd.Timedelta | str = pd.Timedelta(1, \"T\"),\n"
     ]
    }
   ],
   "source": [
    "#Finrl utilities\n",
    "from finrl import config\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37161da-a220-490f-9b67-6acfe3b850e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Utilities\n",
    "import datetime\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c54ce5-396f-42fb-a582-bc80abd87822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make finrl imports accessible\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b012c6e-f473-4110-852f-de9cee7ad206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup libraries\n",
    "from __future__ import annotations\n",
    "#postponed evaluation of type annotations and evaluation available at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c72d02-9a7c-43fe-a432-6921f1d86a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other imports will be used wherever applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfed73f-b71d-450e-8532-471fc33abde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symbols of BSE SENSEX30 whose data is to be downloaded\n",
    "# symbols = [\n",
    "#     'AXISBANK.BO', 'BAJAJ-AUTO.BO', 'BAJFINANCE.BO', 'BAJAJFINSV.BO',\n",
    "#     'BHARTIARTL.BO', 'DRREDDY.BO', 'HCLTECH.BO', 'JSWSTEEL.BO', 'HDFCBANK.BO',\n",
    "#     'HINDUNILVR.BO', 'ICICIBANK.BO', 'INDUSINDBK.BO', 'INFY.BO', 'ITC.BO',\n",
    "#     'KOTAKBANK.BO', 'LT.BO', 'M&M.BO', 'MARUTI.BO', 'NESTLEIND.BO',\n",
    "#     'NTPC.BO', 'ONGC.BO', 'POWERGRID.BO', 'RELIANCE.BO', 'SBIN.BO',\n",
    "#     'SUNPHARMA.BO', 'TCS.BO', 'TECHM.BO', 'TITAN.BO', 'ULTRACEMCO.BO','ASIANPAINT.BO'\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09ec60f-d1f4-4b21-97a6-60fe0c7cc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globally accesible training and trading s/e\n",
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2020-07-01'\n",
    "TRADE_START_DATE = '2020-07-01'\n",
    "TRADE_END_DATE = '2023-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70746a8e-df0e-49b5-a146-21dab4e23a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How we downloaded the data\n",
    "# df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                                 end_date = TRADE_END_DATE,\n",
    "#                                 ticker_list = symbols).fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecee02-4dd1-485e-8d14-f77c820c7b47",
   "metadata": {},
   "source": [
    "### 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b33b42-1022-48ba-9bb4-724b1fa70c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_csv('datasets/BSE30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c5e44b-1124-4426-87de-925b8c8fff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close   volume  \\\n",
       "0  2009-01-02   90.750000   90.750000   88.550003   48.861801    19140   \n",
       "1  2009-01-02  105.800003  109.599998  103.459999   71.914917  4536215   \n",
       "2  2009-01-02  206.050003  210.500000  196.500000  158.413025    52648   \n",
       "3  2009-01-02   15.140000   15.800000   14.975000   13.401811   136590   \n",
       "4  2009-01-02    6.660000    6.970000    6.350000    2.746401   274220   \n",
       "\n",
       "             tic  day  \n",
       "0  ASIANPAINT.BO    4  \n",
       "1    AXISBANK.BO    4  \n",
       "2  BAJAJ-AUTO.BO    4  \n",
       "3  BAJAJFINSV.BO    4  \n",
       "4  BAJFINANCE.BO    4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19eecd6d-8e85-4f7e-a6b3-542e23cab110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105703 entries, 0 to 105702\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    105703 non-null  object \n",
      " 1   open    105703 non-null  float64\n",
      " 2   high    105703 non-null  float64\n",
      " 3   low     105703 non-null  float64\n",
      " 4   close   105703 non-null  float64\n",
      " 5   volume  105703 non-null  int64  \n",
      " 6   tic     105703 non-null  object \n",
      " 7   day     105703 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d14f0-5205-4096-a6e5-19151dc53ebc",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febd40c0-9d74-44a1-9fcf-a3b6f7b7bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vansh\\Downloads\\BTP-2-4-24\\dataprocessing.py:236: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_price_pivot = df_price_pivot.pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "from finrl.config import INDICATORS\n",
    "from dataprocessing import FeatureEngineer, load_dataset, data_split, convert_to_datetime\n",
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                      tech_indicator_list = INDICATORS,\n",
    "                      use_vix=False,\n",
    "                      use_turbulence=True,\n",
    "                      user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083563ce-5668-49e3-abed-4c42a4bfa9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.068260</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105698</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>992.500000</td>\n",
       "      <td>979.250000</td>\n",
       "      <td>986.799988</td>\n",
       "      <td>26056</td>\n",
       "      <td>SUNPHARMA.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.263414</td>\n",
       "      <td>1019.314408</td>\n",
       "      <td>965.265603</td>\n",
       "      <td>50.085294</td>\n",
       "      <td>14.481255</td>\n",
       "      <td>1.567920</td>\n",
       "      <td>983.446670</td>\n",
       "      <td>985.046100</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105699</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3197.149902</td>\n",
       "      <td>3175.769043</td>\n",
       "      <td>51644</td>\n",
       "      <td>TCS.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-15.398183</td>\n",
       "      <td>3235.633708</td>\n",
       "      <td>3045.249324</td>\n",
       "      <td>48.649310</td>\n",
       "      <td>67.966063</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>3131.238102</td>\n",
       "      <td>3257.234477</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105700</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>1026.650024</td>\n",
       "      <td>982.950012</td>\n",
       "      <td>986.955139</td>\n",
       "      <td>279514</td>\n",
       "      <td>TECHM.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>-22.941437</td>\n",
       "      <td>1102.074200</td>\n",
       "      <td>929.293964</td>\n",
       "      <td>44.970681</td>\n",
       "      <td>-99.119890</td>\n",
       "      <td>22.233939</td>\n",
       "      <td>1033.226742</td>\n",
       "      <td>1032.633037</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105701</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2679.300049</td>\n",
       "      <td>2620.050049</td>\n",
       "      <td>2640.399902</td>\n",
       "      <td>32742</td>\n",
       "      <td>TITAN.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>43.161331</td>\n",
       "      <td>2669.834479</td>\n",
       "      <td>2492.325506</td>\n",
       "      <td>60.306098</td>\n",
       "      <td>116.653875</td>\n",
       "      <td>37.463255</td>\n",
       "      <td>2542.391650</td>\n",
       "      <td>2482.099988</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105702</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>7524.950195</td>\n",
       "      <td>7576.549805</td>\n",
       "      <td>7487.549805</td>\n",
       "      <td>7520.226562</td>\n",
       "      <td>8316</td>\n",
       "      <td>ULTRACEMCO.BO</td>\n",
       "      <td>4</td>\n",
       "      <td>28.692164</td>\n",
       "      <td>7774.630825</td>\n",
       "      <td>7303.703648</td>\n",
       "      <td>55.649892</td>\n",
       "      <td>27.765845</td>\n",
       "      <td>3.677975</td>\n",
       "      <td>7441.862826</td>\n",
       "      <td>7301.539185</td>\n",
       "      <td>43.069415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105703 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         open         high          low        close  \\\n",
       "0       2009-01-02    90.750000    90.750000    88.550003    48.861801   \n",
       "1       2009-01-02   105.800003   109.599998   103.459999    71.914917   \n",
       "2       2009-01-02   206.050003   210.500000   196.500000   158.413025   \n",
       "3       2009-01-02    15.140000    15.800000    14.975000    13.401811   \n",
       "4       2009-01-02     6.660000     6.970000     6.350000     2.746401   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "105698  2023-04-28   981.000000   992.500000   979.250000   986.799988   \n",
       "105699  2023-04-28  3208.000000  3227.199951  3197.149902  3175.769043   \n",
       "105700  2023-04-28   983.000000  1026.650024   982.950012   986.955139   \n",
       "105701  2023-04-28  2663.500000  2679.300049  2620.050049  2640.399902   \n",
       "105702  2023-04-28  7524.950195  7576.549805  7487.549805  7520.226562   \n",
       "\n",
       "         volume            tic  day       macd      boll_ub      boll_lb  \\\n",
       "0         19140  ASIANPAINT.BO    4   0.000000    50.523346    48.068260   \n",
       "1       4536215    AXISBANK.BO    4   0.000000    50.523346    48.068260   \n",
       "2         52648  BAJAJ-AUTO.BO    4   0.000000    50.523346    48.068260   \n",
       "3        136590  BAJAJFINSV.BO    4   0.000000    50.523346    48.068260   \n",
       "4        274220  BAJFINANCE.BO    4   0.000000    50.523346    48.068260   \n",
       "...         ...            ...  ...        ...          ...          ...   \n",
       "105698    26056   SUNPHARMA.BO    4  -0.263414  1019.314408   965.265603   \n",
       "105699    51644         TCS.BO    4 -15.398183  3235.633708  3045.249324   \n",
       "105700   279514       TECHM.BO    4 -22.941437  1102.074200   929.293964   \n",
       "105701    32742       TITAN.BO    4  43.161331  2669.834479  2492.325506   \n",
       "105702     8316  ULTRACEMCO.BO    4  28.692164  7774.630825  7303.703648   \n",
       "\n",
       "            rsi_30      cci_30       dx_30  close_30_sma  close_60_sma  \\\n",
       "0       100.000000   66.666667  100.000000     48.861801     48.861801   \n",
       "1       100.000000   66.666667  100.000000     71.914917     71.914917   \n",
       "2       100.000000   66.666667  100.000000    158.413025    158.413025   \n",
       "3       100.000000   66.666667  100.000000     13.401811     13.401811   \n",
       "4       100.000000   66.666667  100.000000      2.746401      2.746401   \n",
       "...            ...         ...         ...           ...           ...   \n",
       "105698   50.085294   14.481255    1.567920    983.446670    985.046100   \n",
       "105699   48.649310   67.966063    0.407494   3131.238102   3257.234477   \n",
       "105700   44.970681  -99.119890   22.233939   1033.226742   1032.633037   \n",
       "105701   60.306098  116.653875   37.463255   2542.391650   2482.099988   \n",
       "105702   55.649892   27.765845    3.677975   7441.862826   7301.539185   \n",
       "\n",
       "        turbulence  \n",
       "0         0.000000  \n",
       "1         0.000000  \n",
       "2         0.000000  \n",
       "3         0.000000  \n",
       "4         0.000000  \n",
       "...            ...  \n",
       "105698   43.069415  \n",
       "105699   43.069415  \n",
       "105700   43.069415  \n",
       "105701   43.069415  \n",
       "105702   43.069415  \n",
       "\n",
       "[105703 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b299a545-307a-4d24-a530-9c7a1e0e84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b45789e-5f8a-4a0d-a1ba-070d4601b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df[\"tic\"].unique().tolist()\n",
    "# only apply to daily level data, need to fix for minute level\n",
    "list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "df_full = df_full[df_full['date'].isin(df['date'])]\n",
    "df_full = df_full.sort_values(['date','tic'])\n",
    "df_full = df_full.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe4ccb1a-fe6a-41e1-95fe-8a3363465c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 105900 entries, 0 to 156899\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   date          105900 non-null  object \n",
      " 1   tic           105900 non-null  object \n",
      " 2   open          105900 non-null  float64\n",
      " 3   high          105900 non-null  float64\n",
      " 4   low           105900 non-null  float64\n",
      " 5   close         105900 non-null  float64\n",
      " 6   volume        105900 non-null  float64\n",
      " 7   day           105900 non-null  float64\n",
      " 8   macd          105900 non-null  float64\n",
      " 9   boll_ub       105900 non-null  float64\n",
      " 10  boll_lb       105900 non-null  float64\n",
      " 11  rsi_30        105900 non-null  float64\n",
      " 12  cci_30        105900 non-null  float64\n",
      " 13  dx_30         105900 non-null  float64\n",
      " 14  close_30_sma  105900 non-null  float64\n",
      " 15  close_60_sma  105900 non-null  float64\n",
      " 16  turbulence    105900 non-null  float64\n",
      "dtypes: float64(15), object(2)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f2577b7-eabd-4f2c-a467-cb5584c94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05041644-b750-457e-81c5-29c56fc1d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>88.550003</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>19140.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>48.861801</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>105.800003</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>103.459999</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>4536215.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>71.914917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>206.050003</td>\n",
       "      <td>210.500000</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>52648.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>158.413025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>15.140000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>136590.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>13.401811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>274220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.523346</td>\n",
       "      <td>48.06826</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>2.746401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic        open        high         low       close  \\\n",
       "0  2009-01-02  ASIANPAINT.BO   90.750000   90.750000   88.550003   48.861801   \n",
       "1  2009-01-02    AXISBANK.BO  105.800003  109.599998  103.459999   71.914917   \n",
       "2  2009-01-02  BAJAJ-AUTO.BO  206.050003  210.500000  196.500000  158.413025   \n",
       "3  2009-01-02  BAJAJFINSV.BO   15.140000   15.800000   14.975000   13.401811   \n",
       "4  2009-01-02  BAJFINANCE.BO    6.660000    6.970000    6.350000    2.746401   \n",
       "\n",
       "      volume  day  macd    boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0    19140.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "1  4536215.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "2    52648.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "3   136590.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "4   274220.0  4.0   0.0  50.523346  48.06826   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  turbulence  \n",
       "0     48.861801     48.861801         0.0  \n",
       "1     71.914917     71.914917         0.0  \n",
       "2    158.413025    158.413025         0.0  \n",
       "3     13.401811     13.401811         0.0  \n",
       "4      2.746401      2.746401         0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "067ab770-a250-4ae6-9192-79a47e011ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105900, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d8ef628-f80f-4d6d-9a2f-b626ad01064e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e81504d-0a4a-47c0-aeb3-ecda859ff39b",
   "metadata": {},
   "source": [
    "### 4.Splitting Training and Trading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28d66621-48cf-40ea-b98d-5b262d41fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77550\n",
      "21120\n"
     ]
    }
   ],
   "source": [
    "train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(df, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76538de6-2554-4a7f-b69b-7f1303363465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_data.csv')\n",
    "trade.to_csv('trade_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5484b-52c9-41ed-aa33-f6aa953ac261",
   "metadata": {},
   "source": [
    "### 5. Construction of Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c6cce40-87e6-410c-ac31-d555f17adaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TradingEnv import StockTradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db88fde3-3088-471d-a275-f30f1c22f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "490ac2e0-422b-4f0d-9d59-c7a13738bb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ASIANPAINT.BO</td>\n",
       "      <td>173.800003</td>\n",
       "      <td>179.990005</td>\n",
       "      <td>173.800003</td>\n",
       "      <td>113.311302</td>\n",
       "      <td>26700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.051069</td>\n",
       "      <td>115.089549</td>\n",
       "      <td>104.640905</td>\n",
       "      <td>66.436248</td>\n",
       "      <td>113.218646</td>\n",
       "      <td>24.458130</td>\n",
       "      <td>108.824595</td>\n",
       "      <td>104.144379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AXISBANK.BO</td>\n",
       "      <td>199.800003</td>\n",
       "      <td>199.800003</td>\n",
       "      <td>197.600006</td>\n",
       "      <td>142.226456</td>\n",
       "      <td>658270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.338474</td>\n",
       "      <td>151.029051</td>\n",
       "      <td>132.164238</td>\n",
       "      <td>52.578761</td>\n",
       "      <td>-1.919545</td>\n",
       "      <td>2.331440</td>\n",
       "      <td>142.339130</td>\n",
       "      <td>140.995590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>BAJAJ-AUTO.BO</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>687.819336</td>\n",
       "      <td>71150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.282086</td>\n",
       "      <td>707.370571</td>\n",
       "      <td>641.819761</td>\n",
       "      <td>61.119288</td>\n",
       "      <td>90.337046</td>\n",
       "      <td>15.068862</td>\n",
       "      <td>655.815855</td>\n",
       "      <td>622.730791</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>BAJAJFINSV.BO</td>\n",
       "      <td>34.900002</td>\n",
       "      <td>36.080002</td>\n",
       "      <td>34.799999</td>\n",
       "      <td>31.331820</td>\n",
       "      <td>1119010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473058</td>\n",
       "      <td>30.449640</td>\n",
       "      <td>27.363217</td>\n",
       "      <td>60.736230</td>\n",
       "      <td>321.150339</td>\n",
       "      <td>46.461213</td>\n",
       "      <td>28.700716</td>\n",
       "      <td>28.163338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>BAJFINANCE.BO</td>\n",
       "      <td>33.270000</td>\n",
       "      <td>34.389999</td>\n",
       "      <td>33.270000</td>\n",
       "      <td>16.682077</td>\n",
       "      <td>221680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568160</td>\n",
       "      <td>16.397749</td>\n",
       "      <td>14.096924</td>\n",
       "      <td>68.269383</td>\n",
       "      <td>212.436642</td>\n",
       "      <td>27.581496</td>\n",
       "      <td>14.887369</td>\n",
       "      <td>14.188843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date            tic        open        high         low       close  \\\n",
       "0  2010-01-04  ASIANPAINT.BO  173.800003  179.990005  173.800003  113.311302   \n",
       "0  2010-01-04    AXISBANK.BO  199.800003  199.800003  197.600006  142.226456   \n",
       "0  2010-01-04  BAJAJ-AUTO.BO  885.000000  886.000000  865.000000  687.819336   \n",
       "0  2010-01-04  BAJAJFINSV.BO   34.900002   36.080002   34.799999   31.331820   \n",
       "0  2010-01-04  BAJFINANCE.BO   33.270000   34.389999   33.270000   16.682077   \n",
       "\n",
       "      volume  day       macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0    26700.0  0.0   2.051069  115.089549  104.640905  66.436248  113.218646   \n",
       "0   658270.0  0.0  -0.338474  151.029051  132.164238  52.578761   -1.919545   \n",
       "0    71150.0  0.0  16.282086  707.370571  641.819761  61.119288   90.337046   \n",
       "0  1119010.0  0.0   0.473058   30.449640   27.363217  60.736230  321.150339   \n",
       "0   221680.0  0.0   0.568160   16.397749   14.096924  68.269383  212.436642   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  24.458130    108.824595    104.144379         0.0  \n",
       "0   2.331440    142.339130    140.995590         0.0  \n",
       "0  15.068862    655.815855    622.730791         0.0  \n",
       "0  46.461213     28.700716     28.163338         0.0  \n",
       "0  27.581496     14.887369     14.188843         0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96cf6369-0195-453c-be44-674a48ac5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd613e04-ff28-40c4-8eba-fa0fcafdb7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da8507ba-f46f-43df-bc16-9ad39026c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d88eb5-3fdf-4d97-87e6-6fac63e83859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from stable_baselines3.common.logger import configure\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01cfb65-c9c6-4920-a99e-4fb4cb34451b",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90aaf254-10a4-427b-87d0-a51677ae73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81600ba0-a53e-4def-9010-6fd138f496a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 56           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -5.68        |\n",
      "|    reward             | -0.042397726 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.259        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 56         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.22314343 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 56         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 169        |\n",
      "|    reward             | -1.3621267 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 16.6       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -78      |\n",
      "|    reward             | 298.4354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 7.33     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 86.1       |\n",
      "|    reward             | -26.367573 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 64.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 6.56e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -18.7     |\n",
      "|    reward             | 4.1787834 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.34      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 77.6       |\n",
      "|    reward             | -1.5944586 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.53       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 225         |\n",
      "|    reward             | -0.83696175 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 32.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    reward             | 2.5612156 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.83      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.7    |\n",
      "|    explained_variance | -0.0615  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 149      |\n",
      "|    reward             | 5.037634 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 99         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 9.8        |\n",
      "|    reward             | -0.1947339 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 120       |\n",
      "|    reward             | -2.481694 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.11      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 117        |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 64.2       |\n",
      "|    reward             | -4.1581144 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.4        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -911      |\n",
      "|    reward             | 1.6713936 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 529       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 359        |\n",
      "|    reward             | -2.3588605 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 90.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 62.3       |\n",
      "|    reward             | 0.11445383 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.43       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -33       |\n",
      "|    reward             | 1.3251541 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.81      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 472      |\n",
      "|    reward             | 3.139194 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 118      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -457      |\n",
      "|    reward             | 2.0654857 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 112       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 108       |\n",
      "|    reward             | 1.1532799 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -7.72      |\n",
      "|    reward             | 0.58953494 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.195      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -0.00413    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 126         |\n",
      "|    reward             | -0.34756705 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 181       |\n",
      "|    reward             | 3.3412867 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 22.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 11.6       |\n",
      "|    reward             | -4.3097863 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.884      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 71.6      |\n",
      "|    reward             | -5.363316 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 17.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -0.00227  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -81.5     |\n",
      "|    reward             | 1.5864182 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.04      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 76.4        |\n",
      "|    reward             | 0.024669766 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.55        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 204        |\n",
      "|    reward             | -3.4160612 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 27.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | 179        |\n",
      "|    reward             | 0.12898622 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 270        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 27.7       |\n",
      "|    reward             | 0.64695805 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 301         |\n",
      "|    reward             | -0.90637934 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 68.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -5.51      |\n",
      "|    reward             | 0.25541192 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.413      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 303         |\n",
      "|    reward             | -0.75915635 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 50.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -167      |\n",
      "|    reward             | 1.1833186 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 28.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 315       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 239       |\n",
      "|    reward             | 5.1817985 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 35.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | 68.6       |\n",
      "|    reward             | 0.11895505 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 333        |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -234       |\n",
      "|    reward             | -0.6198487 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 28.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 342       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -157      |\n",
      "|    reward             | 2.8179057 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 14.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 351       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 50.1      |\n",
      "|    reward             | 3.8212526 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 33.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 141      |\n",
      "|    reward             | 9.746553 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 369        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 20.7       |\n",
      "|    reward             | -1.5339803 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.46       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 56.4      |\n",
      "|    reward             | 2.1064065 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.03      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 387         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -101        |\n",
      "|    reward             | -0.84109324 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 7.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 324        |\n",
      "|    reward             | -0.7429404 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 64.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 405        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 533        |\n",
      "|    reward             | -1.9695709 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 165        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -83.5    |\n",
      "|    reward             | 3.457529 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "day: 2584, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5292028.65\n",
      "total_reward: 4292028.65\n",
      "total_cost: 11859.44\n",
      "total_trades: 43655\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 423        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -68.5      |\n",
      "|    reward             | -2.5120242 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.99       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -29.9      |\n",
      "|    reward             | 0.63604474 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.757      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 441       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -135      |\n",
      "|    reward             | 3.942583  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 17.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 450        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 35         |\n",
      "|    reward             | -0.3342607 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.813      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 460        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 197        |\n",
      "|    reward             | -0.4442813 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 23         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 469       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -0.000126 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 27.5      |\n",
      "|    reward             | 0.968167  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.11      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 478        |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 112        |\n",
      "|    reward             | 0.09961546 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 9.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 487         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -9.57       |\n",
      "|    reward             | -0.71684086 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 5.46        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 343        |\n",
      "|    reward             | -2.7067456 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 93.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 506        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 30.6       |\n",
      "|    reward             | -7.4476066 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 28.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | 4.37e-05    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -62.1       |\n",
      "|    reward             | -0.52084786 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 524         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 195         |\n",
      "|    reward             | -0.17483193 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 28.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -82.6      |\n",
      "|    reward             | -1.3103094 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 8.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 542       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -297      |\n",
      "|    reward             | 0.8832117 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 70.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 551       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 61.6      |\n",
      "|    reward             | 2.5856688 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.65      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 55        |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 560       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 810       |\n",
      "|    reward             | 5.7035847 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 389       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 55         |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 569        |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 45.7       |\n",
      "|    reward             | 0.10304965 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 579         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -122        |\n",
      "|    reward             | -0.30521715 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 11          |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 55           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 587          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 21.3         |\n",
      "|    reward             | -0.063566655 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 2            |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 597         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -50.1       |\n",
      "|    reward             | -0.60402864 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 3.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 55          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 608         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 343         |\n",
      "|    reward             | -0.86517966 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 57.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 618        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -22.9      |\n",
      "|    reward             | -1.1941769 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 629       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -25.9     |\n",
      "|    reward             | 2.5239706 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 639       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -111      |\n",
      "|    reward             | 2.8129659 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 650       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | 1.4095851 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 659      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.855   |\n",
      "|    reward             | 5.735496 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 2.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 668      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -30.6    |\n",
      "|    reward             | 2.516352 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 677       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 50.5      |\n",
      "|    reward             | 1.0879294 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.95      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 686        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -626       |\n",
      "|    reward             | -7.6820407 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 232        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 695        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -25.8      |\n",
      "|    reward             | 0.30563524 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.72       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 706       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -211      |\n",
      "|    reward             | 4.0911627 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 27.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 716        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -70.7      |\n",
      "|    reward             | -1.5158892 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 54          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 727         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 1.26        |\n",
      "|    reward             | -0.44011998 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 737        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 5.73       |\n",
      "|    reward             | 0.35158694 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 748      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -182     |\n",
      "|    reward             | 1.407456 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 54          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 757         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -93.5       |\n",
      "|    reward             | -0.59443116 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 7.34        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 766       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -47.2     |\n",
      "|    reward             | -5.510158 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.63      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 54          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 775         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -40.1       |\n",
      "|    reward             | -0.61630774 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 54          |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 46.2        |\n",
      "|    reward             | 0.023934107 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 5.01        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 793        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | -1.4718361 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.12       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 54       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 801      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 152      |\n",
      "|    reward             | 5.258223 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 54          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 810         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -10.3       |\n",
      "|    reward             | -0.71412563 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -54.8      |\n",
      "|    reward             | -1.2821208 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 54           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 828          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -39.9        |\n",
      "|    reward             | 0.0064231353 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 837       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 595       |\n",
      "|    reward             | 4.0866995 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 201       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 846        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 110        |\n",
      "|    reward             | -5.6724586 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 10.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 855       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 156       |\n",
      "|    reward             | 7.7459993 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 25.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 865        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -111       |\n",
      "|    reward             | -1.3191379 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 7.53       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 874       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -206      |\n",
      "|    reward             | 1.2758216 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 24.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 883       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -253      |\n",
      "|    reward             | 3.2034469 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 48.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 892       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 310       |\n",
      "|    reward             | 1.5616322 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 59        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 54        |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 901       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 111       |\n",
      "|    reward             | 4.9700713 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "day: 2584, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4136780.77\n",
      "total_reward: 3136780.77\n",
      "total_cost: 2170.23\n",
      "total_trades: 45886\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 910        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 24.3       |\n",
      "|    reward             | 0.34688148 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 54         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 920        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -39        |\n",
      "|    reward             | -0.8672676 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3c468e6-ae7d-42a0-af6f-c0a6e7f3d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02b3a6-d4ad-4135-bb40-319f9364962e",
   "metadata": {},
   "source": [
    "### Testing A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e7bc5-7e93-409f-9573-3c3f01cba845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "trained_a2c = A2C.load(\"trained_models/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afc9c2-5823-4afb-909a-7a9ab0622662",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad41c5-5076-4f57-bbc2-6649285e78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d6844-a243-4255-9abf-7eb6a471cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01104517-6131-43b1-aaf8-ac8fcd62f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4354a4-3de3-4773-b7f3-9204c8f8bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_a2c.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c673516-c782-44d4-8d3d-d541f5c16863",
   "metadata": {},
   "source": [
    "## DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "790dae9c-e814-4736-a083-0a223218e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ba864a4-5815-4fa1-a0e9-e2f54be94915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 34        |\n",
      "|    time_elapsed    | 296       |\n",
      "|    total_timesteps | 10340     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 37.7      |\n",
      "|    critic_loss     | 32.2      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7755      |\n",
      "|    reward          | 3.9305856 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 31        |\n",
      "|    time_elapsed    | 655       |\n",
      "|    total_timesteps | 20680     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 17        |\n",
      "|    critic_loss     | 8.35      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18095     |\n",
      "|    reward          | 3.9305856 |\n",
      "----------------------------------\n",
      "day: 2584, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4483539.77\n",
      "total_reward: 3483539.77\n",
      "total_cost: 1009.28\n",
      "total_trades: 25812\n",
      "Sharpe: 0.488\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 30        |\n",
      "|    time_elapsed    | 1012      |\n",
      "|    total_timesteps | 31020     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.34      |\n",
      "|    critic_loss     | 4.81      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28435     |\n",
      "|    reward          | 3.9305856 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 31        |\n",
      "|    time_elapsed    | 1333      |\n",
      "|    total_timesteps | 41360     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.13     |\n",
      "|    critic_loss     | 3.36      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38775     |\n",
      "|    reward          | 3.9305856 |\n",
      "----------------------------------\n",
      "day: 2584, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4483539.77\n",
      "total_reward: 3483539.77\n",
      "total_cost: 1009.28\n",
      "total_trades: 25812\n",
      "Sharpe: 0.488\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 32        |\n",
      "|    time_elapsed    | 1608      |\n",
      "|    total_timesteps | 51700     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.71     |\n",
      "|    critic_loss     | 2.52      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 49115     |\n",
      "|    reward          | 3.9305856 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f867d1e0-85e4-469d-a490-3d35ccd15c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c819a-c423-4314-a3f5-3ad4c9e6aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d19496-cbdd-4623-9a5b-8e4bf294c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4b2ad56-2037-45e2-a3a0-4f4e2dccf290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb5f57d-f632-482e-9feb-0f0482565f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 87        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 23        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 4.0592203 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018641617 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | -0.0099     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | -2.159677   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 93         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01949444 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00204   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    reward               | -0.4911504 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 62.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020603677 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0283      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -1.0691344  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023066852 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0518      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -3.1217067  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022772666 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -2.244483   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 75.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016262408 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 2.2637844   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021768956 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0997      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 1.1457258   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022010868 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.23370826  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02112437 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.3      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 138        |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 3.1912692  |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 83.8       |\n",
      "----------------------------------------\n",
      "day: 2584, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2548043.21\n",
      "total_reward: 1548043.21\n",
      "total_cost: 1816639.98\n",
      "total_trades: 62995\n",
      "Sharpe: 0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019484561 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.8670269   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018757598 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 1.2204263   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02018834 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.4      |\n",
      "|    explained_variance   | 0.0897     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 0.49629197 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035004307 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.3765069   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016213335 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 521         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -1.3072859  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046311066 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 0.28919002  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027561057 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.320474    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020947075 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.424583   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020668086 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 0.033359185 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015869807 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.5187614   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 569         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028655048 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -2.9605656  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027514838 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -0.9957301  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3638944.54\n",
      "total_reward: 2638944.54\n",
      "total_cost: 1892322.70\n",
      "total_trades: 62950\n",
      "Sharpe: 0.342\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 97         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 485        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01757014 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.3       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    reward               | -3.1509938 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 208        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 506          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017601084  |\n",
      "|    clip_fraction        | 0.251        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.2         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | -0.061551515 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016975727 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.7874303   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025144424 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0789      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 5.1823115   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019621823 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 1.4977766   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966241 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 458         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.008677103 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968162 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 63.980614   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 8.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019533072 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0025      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -33.163105  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010356357 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 390         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 1.6961972   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339005 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.00446     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.43e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | -0.68038285 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013459545 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.33e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.002246885 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009769364 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.47e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 8.783529    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 740         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023945 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | 9.455886    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 893         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4962386.90\n",
      "total_reward: 3962386.90\n",
      "total_cost: 1628350.45\n",
      "total_trades: 60723\n",
      "Sharpe: 0.483\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020566382 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.00213     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 8.4830065   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 939         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022856992 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 716         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.75767094  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 662         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014955524 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -3.1039412  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018417671 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -1.1225958  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021088347 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    reward               | 0.102188066 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 869         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023542933 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 0.8827302   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 96         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 892        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01777952 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -0.6675529 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 55.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015703835 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0446      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 2.0703394   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 943        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0248465  |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.4       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    reward               | -20.330748 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 132        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 970         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008362107 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 611         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 3.0446172   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 94         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 997        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00456327 |\n",
      "|    clip_fraction        | 0.00903    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.0134     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.34e+03   |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.006     |\n",
      "|    reward               | 0.08670508 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 1.04e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012176418 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 931         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.6272429   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 18565041.83\n",
      "total_reward: 17565041.83\n",
      "total_cost: 1571922.15\n",
      "total_trades: 59438\n",
      "Sharpe: 0.434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010628522 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.12978487  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1080        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011880076 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.00865     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.1436437  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013677685 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -1.4845666  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1136        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014884111 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 1.2779398   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 5.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1163        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018967737 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 773         |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.7137463   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010445684 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.0253      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.07e+03    |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -18.559805  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 7.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015584242 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 714         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 7.440749    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116675 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 590         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 18.989462   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125971 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.73e+03    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -1.4763755  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1299        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011986498 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.3607123   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1327        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012717884 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.32e+03    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 43.014088   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.96e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012323972 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.63e+03    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -16.608868  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.21e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 1383       |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01207923 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | 0.00549    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.38e+03   |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    reward               | -0.2527314 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.35e+04   |\n",
      "----------------------------------------\n",
      "day: 2584, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 26627953.54\n",
      "total_reward: 25627953.54\n",
      "total_cost: 1401550.80\n",
      "total_trades: 57925\n",
      "Sharpe: 0.477\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1410        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011564285 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+04    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.2492746  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1437        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012530673 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+04    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.3352162   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1464        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013804965 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+04    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 244.1249    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1491        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011457941 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.62e+03    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -10.248179  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1518        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026308667 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.00541     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+04    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 1.7162712   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1546        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020880006 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | -0.7976823  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 1573         |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02241113   |\n",
      "|    clip_fraction        | 0.35         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.32e+03     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.031692922 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024806684 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 972         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.74611443 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 7.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1627        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038788136 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 3.6908529   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 86         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 1654       |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899603 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 315        |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.00846   |\n",
      "|    reward               | -5.1034603 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 2.71e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1681        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023305807 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.63258123  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 850         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 1709        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012877064 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 0.2611612   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 7.56e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032109782 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -3.1880398  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3899965.03\n",
      "total_reward: 2899965.03\n",
      "total_cost: 996530.66\n",
      "total_trades: 53917\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017765256 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | -0.5529942  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1790        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555641 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | -0.41650042 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 1817       |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03277135 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.6       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    reward               | -1.915599  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029676326 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | -0.71904254 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020127747 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    reward               | -0.69034123 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1898        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013476102 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 2.3798966   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759398 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 4.627062    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1953        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015066544 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -1.5916415  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017956853 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -0.8279543  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 2007        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015773416 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -2.0808382  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024384923 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 0.31988987  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 2064        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013274232 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -0.25219807 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "day: 2584, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2770992.74\n",
      "total_reward: 1770992.74\n",
      "total_cost: 449698.54\n",
      "total_trades: 48047\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 2091        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011096032 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -0.83965105 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 2118        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012155503 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.2267982   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 85.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 2145        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012608224 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.8338106   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 2173        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159353 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.21277303  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 2200        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016858857 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.7155553  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 93.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 2227         |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129864905 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | 0.17309016   |\n",
      "|    std                  | 1.18         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 2254        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014147153 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | -3.0241158  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 490         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 2283        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023613347 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 0.7739482   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 2310        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015734915 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -0.6703647  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 2338        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013813818 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.4        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.21463184 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 2365        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015853245 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.71934575 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 2392        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013356132 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 1.4985831   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 82         |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 2419       |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01764878 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.4        |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    reward               | 1.1066265  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=200000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f1b6e13-9c3c-42a3-837e-9fed20675311",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc8368-a067-41da-a3c8-c01832ad8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c6817-687a-43eb-b61e-82b4133797b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99cbd1-137c-4b9d-89e8-7930d2554547",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bb4bd-1de7-4b63-b1a7-8075c240d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93902222-3672-46b2-b507-709d244a357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311428e-5efd-4687-a745-e4d63c46900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9775b9-851d-44c0-a54c-690f8c72b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b43d95-5126-4723-9a66-185401b80ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da0694-1230-40db-acf7-167680a0d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab2b83-c8d2-440f-8390-9d65ab4e05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe25012-e974-4ff5-8edf-b1c39737f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff242e-6727-4bf3-90aa-4686ed16682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fea52c-38db-42e6-ad48-a9acbece3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7eb9d-c7df-4d37-b9f4-66c9466e6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
